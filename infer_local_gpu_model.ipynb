{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJzKVsOroYm6Hza1kITcDt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JackeYou/Enjoy_LLM/blob/main/infer_local_gpu_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4veI-j6ATJH"
      },
      "outputs": [],
      "source": [
        "# gpu 本地部署\n",
        "!git clone https://huggingface.co/THUDM/chatglm-6b"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd\n",
        "!git clone https://github.com/JackeYou/ChatGLM-Tuning.git\n",
        "%cd  ChatGLM-Tuning\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "SEiddLmgBAfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from modeling_chatglm import ChatGLMForConditionalGeneration\n",
        "import torch\n",
        "from peft import PeftModel\n",
        "from tokenization_chatglm import ChatGLMTokenizer\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# 加载本地预训练模型\n",
        "torch.set_default_tensor_type(torch.cuda.HalfTensor)\n",
        "BASE_MODEL_DIR = \"/content/chatglm-6b\"\n",
        "gpu_model = ChatGLMForConditionalGeneration.from_pretrained(BASE_MODEL_DIR).half().cuda()\n",
        "tokenizer = ChatGLMTokenizer.from_pretrained(BASE_MODEL_DIR)\n"
      ],
      "metadata": {
        "id": "SLwUDAwcBERg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from cover_alpaca2jsonl import format_example\n",
        "\n",
        "instructions = [\n",
        " {'instruction': '请给出十字路口交通指示灯的三种颜色',\n",
        "  'input': '',\n",
        "  'output': '红色、绿色、黄色。',\n",
        " },\n",
        " {'instruction': '请给出以下资讯3个关键词',\n",
        "  'input': '猪肉概念股大幅拉升，巨星农牧涨停，新五丰连续两日大涨',\n",
        "  'output': '猪肉概念股，巨星农牧，新五丰。',\n",
        " },\n",
        " {'instruction': '以下哪家公司市值最高',\n",
        "  'input': '腾讯、京东、淘宝',\n",
        "  'output': '腾讯公司市值最高。截止2021年4月21日，腾讯公司的市值约为6.78万亿人民币，京东的市值约为1.26万亿人民币，淘宝的市值约为1.8万亿人民币。',\n",
        " },\n",
        " {'instruction': '请给出以下资讯3个关键词',\n",
        "  'input': '隆基绿能董事长：光伏产品短期价格涨跌意义不大，长期看成本一定会越来越低',\n",
        "  'output': '1.隆基绿能，2.光伏产品，3.成本降低',\n",
        " }\n",
        "]\n",
        "with torch.no_grad():\n",
        "    for idx, item in enumerate(instructions):\n",
        "        feature = format_example(item)\n",
        "        input_text = feature['context']\n",
        "        ids = tokenizer.encode(input_text)\n",
        "        input_ids = torch.tensor([ids])\n",
        "        out = gpu_model.generate(\n",
        "            input_ids=input_ids,\n",
        "            max_length=150,\n",
        "            do_sample=False,\n",
        "            temperature=0\n",
        "        )\n",
        "        out_text = tokenizer.decode(out[0])\n",
        "        answer = out_text.replace(input_text, \"\").replace(\"\\nEND\", \"\").strip()\n",
        "        item['infer_answer'] = answer\n",
        "        print(out_text)\n",
        "        print(f\"chatGPT### {idx+1}.Answer:\\n\", item.get('output'), '\\n\\n')"
      ],
      "metadata": {
        "id": "mBPi3sY2BHGE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}